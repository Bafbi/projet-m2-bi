"""
Exemple d'extension de la pipeline dbt avec des commandes supplÃ©mentaires

Ce fichier montre comment ajouter facilement de nouvelles tÃ¢ches dbt
en suivant le mÃªme pattern que pipeline.py.

Pour l'utiliser, copiez les fonctions dont vous avez besoin dans pipeline.py
"""
from prefect import flow, task, get_run_logger
from prefect_dbt.cli.commands import DbtCoreOperation
from pathlib import Path
from prefect_dbt.cli import DbtCliProfile


@task(name="dbt-seed", retries=1)
def load_dbt_seeds(target: str = "dev"):
    """
    Charge les fichiers CSV seeds dans BigQuery (dbt seed)
    
    Les seeds sont des fichiers CSV dans dbt/seeds/ qui sont chargÃ©s
    comme des tables dans votre data warehouse. Utiles pour des
    donnÃ©es de rÃ©fÃ©rence (pays, catÃ©gories, etc.)
    
    Args:
        target: Environnement cible (dev ou prod)
    
    Returns:
        RÃ©sultat de l'exÃ©cution dbt seed
    """
    logger = get_run_logger()
    project_dir = Path(__file__).parent.parent / "dbt"
    profile_block_name = f"dbt-cli-profile-{target}"
    
    logger.info(f"Chargement des seeds depuis le bloc: {profile_block_name}")
    
    try:
        dbt_cli_profile = DbtCliProfile.load(profile_block_name)
        logger.info(f"âœ… Profil chargÃ© pour les seeds")
    except ValueError as e:
        logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
        raise ValueError(
            f"Le bloc '{profile_block_name}' n'existe pas. "
            f"ExÃ©cutez: uv run python -m infrastructure.setup_profiles"
        ) from e
    
    result = DbtCoreOperation(
        commands=["dbt seed"],
        project_dir=str(project_dir),
        overwrite_profiles=True,
        dbt_cli_profile=dbt_cli_profile,
    ).run()
    
    return result


@task(name="dbt-docs-generate")
def generate_dbt_docs(target: str = "dev"):
    """
    GÃ©nÃ¨re la documentation dbt (dbt docs generate)
    
    CrÃ©e un site web de documentation pour vos modÃ¨les dbt.
    La documentation inclut le lineage (dÃ©pendances entre modÃ¨les),
    les descriptions, les tests, etc.
    
    Args:
        target: Environnement cible (dev ou prod)
    
    Returns:
        RÃ©sultat de la gÃ©nÃ©ration de docs
    """
    logger = get_run_logger()
    project_dir = Path(__file__).parent.parent / "dbt"
    profile_block_name = f"dbt-cli-profile-{target}"
    
    logger.info(f"GÃ©nÃ©ration de la documentation dbt...")
    
    try:
        dbt_cli_profile = DbtCliProfile.load(profile_block_name)
        logger.info(f"âœ… Profil chargÃ© pour la gÃ©nÃ©ration de docs")
    except ValueError as e:
        logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
        raise ValueError(
            f"Le bloc '{profile_block_name}' n'existe pas. "
            f"ExÃ©cutez: uv run python -m infrastructure.setup_profiles"
        ) from e
    
    result = DbtCoreOperation(
        commands=["dbt docs generate"],
        project_dir=str(project_dir),
        overwrite_profiles=True,
        dbt_cli_profile=dbt_cli_profile,
    ).run()
    
    return result


@task(name="dbt-snapshot")
def run_dbt_snapshots(target: str = "dev"):
    """
    ExÃ©cute les snapshots dbt (dbt snapshot)
    
    Les snapshots permettent de capturer l'Ã©tat d'une table Ã  un moment donnÃ©
    (Type 2 Slowly Changing Dimensions). Utile pour tracker l'historique
    des changements dans vos donnÃ©es source.
    
    Args:
        target: Environnement cible (dev ou prod)
    
    Returns:
        RÃ©sultat de l'exÃ©cution des snapshots
    """
    logger = get_run_logger()
    project_dir = Path(__file__).parent.parent / "dbt"
    profile_block_name = f"dbt-cli-profile-{target}"
    
    logger.info(f"ExÃ©cution des snapshots dbt...")
    
    try:
        dbt_cli_profile = DbtCliProfile.load(profile_block_name)
        logger.info(f"âœ… Profil chargÃ© pour les snapshots")
    except ValueError as e:
        logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
        raise ValueError(
            f"Le bloc '{profile_block_name}' n'existe pas. "
            f"ExÃ©cutez: uv run python -m infrastructure.setup_profiles"
        ) from e
    
    result = DbtCoreOperation(
        commands=["dbt snapshot"],
        project_dir=str(project_dir),
        overwrite_profiles=True,
        dbt_cli_profile=dbt_cli_profile,
    ).run()
    
    return result


@task(name="dbt-run-models-specific")
def run_specific_models(models: str, target: str = "dev"):
    """
    ExÃ©cute seulement certains modÃ¨les dbt (dbt run --select)
    
    Permet de ne run que certains modÃ¨les plutÃ´t que tout le projet.
    Utile pour tester rapidement un modÃ¨le spÃ©cifique.
    
    Args:
        models: SÃ©lection des modÃ¨les (ex: "my_model", "tag:daily", "path:marts/")
        target: Environnement cible (dev ou prod)
    
    Returns:
        RÃ©sultat de l'exÃ©cution
        
    Exemples:
        run_specific_models("my_model", target="dev")  # Un modÃ¨le
        run_specific_models("tag:daily", target="prod")  # Tous les modÃ¨les taguÃ©s "daily"
        run_specific_models("path:marts/", target="dev")  # Tous les modÃ¨les dans marts/
    """
    logger = get_run_logger()
    project_dir = Path(__file__).parent.parent / "dbt"
    profile_block_name = f"dbt-cli-profile-{target}"
    
    logger.info(f"ExÃ©cution des modÃ¨les sÃ©lectionnÃ©s: {models}")
    
    try:
        dbt_cli_profile = DbtCliProfile.load(profile_block_name)
        logger.info(f"âœ… Profil chargÃ©")
    except ValueError as e:
        logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
        raise ValueError(
            f"Le bloc '{profile_block_name}' n'existe pas. "
            f"ExÃ©cutez: uv run python -m infrastructure.setup_profiles"
        ) from e
    
    result = DbtCoreOperation(
        commands=[f"dbt run --select {models}"],
        project_dir=str(project_dir),
        overwrite_profiles=True,
        dbt_cli_profile=dbt_cli_profile,
    ).run()
    
    return result


@task(name="dbt-freshness")
def check_source_freshness(target: str = "dev"):
    """
    VÃ©rifie la fraÃ®cheur des sources dbt (dbt source freshness)
    
    VÃ©rifie si vos sources de donnÃ©es sont Ã  jour selon les rÃ¨gles
    dÃ©finies dans vos fichiers de sources (sources.yml).
    
    Args:
        target: Environnement cible (dev ou prod)
    
    Returns:
        RÃ©sultat de la vÃ©rification de fraÃ®cheur
    """
    logger = get_run_logger()
    project_dir = Path(__file__).parent.parent / "dbt"
    profile_block_name = f"dbt-cli-profile-{target}"
    
    logger.info(f"VÃ©rification de la fraÃ®cheur des sources...")
    
    try:
        dbt_cli_profile = DbtCliProfile.load(profile_block_name)
        logger.info(f"âœ… Profil chargÃ©")
    except ValueError as e:
        logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
        raise ValueError(
            f"Le bloc '{profile_block_name}' n'existe pas. "
            f"ExÃ©cutez: uv run python -m infrastructure.setup_profiles"
        ) from e
    
    result = DbtCoreOperation(
        commands=["dbt source freshness"],
        project_dir=str(project_dir),
        overwrite_profiles=True,
        dbt_cli_profile=dbt_cli_profile,
    ).run()
    
    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# EXEMPLES DE FLOWS COMPOSÃ‰S
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@flow(name="pipeline-dbt-complete-with-seeds", log_prints=True)
def dbt_pipeline_with_seeds(target: str = "dev"):
    """
    Pipeline complÃ¨te incluant les seeds
    
    Ordre d'exÃ©cution :
    1. Load seeds (donnÃ©es de rÃ©fÃ©rence)
    2. Run models (transformations)
    3. Test models (qualitÃ©)
    """
    logger = get_run_logger()
    
    logger.info(f"ğŸš€ Pipeline complÃ¨te avec seeds (environnement: {target})")
    
    # 1. Charger les seeds
    logger.info("ğŸ“¥ Ã‰tape 1/3 : Chargement des seeds...")
    seed_result = load_dbt_seeds(target=target)
    
    # 2. Run les modÃ¨les
    logger.info("ğŸ“Š Ã‰tape 2/3 : ExÃ©cution des modÃ¨les...")
    from prefect_flows.pipeline import run_dbt_models
    run_result = run_dbt_models(target=target)
    
    # 3. Tester
    logger.info("ğŸ§ª Ã‰tape 3/3 : Tests...")
    from prefect_flows.pipeline import test_dbt_models
    test_result = test_dbt_models(target=target)
    
    logger.info(f"âœ… Pipeline avec seeds terminÃ©e !")
    
    return {
        "target": target,
        "seed": seed_result,
        "run": run_result,
        "test": test_result,
    }


@flow(name="pipeline-dbt-with-docs", log_prints=True)
def dbt_pipeline_with_documentation(target: str = "dev"):
    """
    Pipeline qui gÃ©nÃ¨re aussi la documentation
    
    Ordre d'exÃ©cution :
    1. Run models
    2. Test models
    3. Generate docs
    """
    logger = get_run_logger()
    
    logger.info(f"ğŸš€ Pipeline avec documentation (environnement: {target})")
    
    # 1. Run
    logger.info("ğŸ“Š Ã‰tape 1/3 : ExÃ©cution des modÃ¨les...")
    from prefect_flows.pipeline import run_dbt_models
    run_result = run_dbt_models(target=target)
    
    # 2. Test
    logger.info("ğŸ§ª Ã‰tape 2/3 : Tests...")
    from prefect_flows.pipeline import test_dbt_models
    test_result = test_dbt_models(target=target)
    
    # 3. Generate docs
    logger.info("ğŸ“š Ã‰tape 3/3 : GÃ©nÃ©ration de la documentation...")
    docs_result = generate_dbt_docs(target=target)
    
    logger.info(f"âœ… Pipeline avec documentation terminÃ©e !")
    logger.info(f"ğŸ“– Pour voir la documentation : cd dbt && dbt docs serve")
    
    return {
        "target": target,
        "run": run_result,
        "test": test_result,
        "docs": docs_result,
    }


@flow(name="pipeline-dbt-daily-with-snapshots", log_prints=True)
def dbt_daily_pipeline(target: str = "prod"):
    """
    Pipeline quotidienne de production
    
    Ordre d'exÃ©cution :
    1. Check source freshness (vÃ©rifier que les donnÃ©es sont Ã  jour)
    2. Run snapshots (capturer l'historique)
    3. Run models (transformations)
    4. Test models (qualitÃ©)
    5. Generate docs (documentation)
    """
    logger = get_run_logger()
    
    logger.info(f"ğŸš€ Pipeline quotidienne (environnement: {target})")
    
    # 1. VÃ©rifier la fraÃ®cheur des sources
    logger.info("ğŸ” Ã‰tape 1/5 : VÃ©rification de la fraÃ®cheur des sources...")
    freshness_result = check_source_freshness(target=target)
    
    # 2. Snapshots
    logger.info("ğŸ“¸ Ã‰tape 2/5 : ExÃ©cution des snapshots...")
    snapshot_result = run_dbt_snapshots(target=target)
    
    # 3. Run
    logger.info("ğŸ“Š Ã‰tape 3/5 : ExÃ©cution des modÃ¨les...")
    from prefect_flows.pipeline import run_dbt_models
    run_result = run_dbt_models(target=target)
    
    # 4. Test
    logger.info("ğŸ§ª Ã‰tape 4/5 : Tests...")
    from prefect_flows.pipeline import test_dbt_models
    test_result = test_dbt_models(target=target)
    
    # 5. Docs
    logger.info("ğŸ“š Ã‰tape 5/5 : GÃ©nÃ©ration de la documentation...")
    docs_result = generate_dbt_docs(target=target)
    
    logger.info(f"âœ… Pipeline quotidienne terminÃ©e !")
    
    return {
        "target": target,
        "freshness": freshness_result,
        "snapshots": snapshot_result,
        "run": run_result,
        "test": test_result,
        "docs": docs_result,
    }


if __name__ == "__main__":
    """
    Exemples d'exÃ©cution
    """
    # Pipeline simple avec seeds
    # dbt_pipeline_with_seeds(target="dev")
    
    # Pipeline avec documentation
    # dbt_pipeline_with_documentation(target="dev")
    
    # Pipeline quotidienne complÃ¨te (prod)
    # dbt_daily_pipeline(target="prod")
    
    # Run de modÃ¨les spÃ©cifiques
    # run_specific_models("my_first_dbt_model", target="dev")
    
    print("âœ¨ Exemples de pipelines disponibles !")
    print("DÃ©commentez les lignes ci-dessus pour les tester.")

