# Explication de l'Architecture Pipeline Prefect + dbt

## ğŸ¯ ProblÃ¨me Initial

Votre `pipeline.py` essayait de charger un profil dbt hardcodÃ© avec :

```python
dbt_cli_profile = DbtCliProfile.load("profile").get_profile()
```

**ProblÃ¨me** : Ce bloc "profile" n'existait pas, car vos flows de setup crÃ©ent des blocs avec des noms spÃ©cifiques (`dbt-cli-profile-dev`, `dbt-cli-profile-prod`).

## âœ… Solution ImplÃ©mentÃ©e

### 1. Architecture Ã  Deux Niveaux

J'ai modifiÃ© votre code pour suivre une **architecture en deux phases** :

```
Phase 1 : SETUP (une fois)              Phase 2 : EXECUTION (Ã  chaque run)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
infrastructure/setup_profiles/   â†’     prefect_flows/pipeline.py
CrÃ©e les blocs Prefect                 Utilise les blocs crÃ©Ã©s
```

### 2. Modifications ApportÃ©es

#### A) Ajout du ParamÃ¨tre `target`

**Avant** :
```python
def run_dbt_models():
    dbt_cli_profile = DbtCliProfile.load("profile")  # Bloc hardcodÃ© âŒ
```

**AprÃ¨s** :
```python
def run_dbt_models(target: str = "dev"):
    profile_block_name = f"dbt-cli-profile-{target}"  # Dynamique âœ…
    dbt_cli_profile = DbtCliProfile.load(profile_block_name)
```

**Pourquoi ?** 
- âœ… FlexibilitÃ© : Un seul code pour dev ET prod
- âœ… Ã‰volutivitÃ© : Facile d'ajouter staging, test, etc.
- âœ… Convention : Suit le pattern de nommage dÃ©fini dans `flows.py`

#### B) Chargement Dynamique des Blocs

**Le Pattern** :
```python
# 1. Construction du nom selon la convention
profile_block_name = f"dbt-cli-profile-{target}"
# Si target="dev"  â†’ "dbt-cli-profile-dev"
# Si target="prod" â†’ "dbt-cli-profile-prod"

# 2. Chargement du bloc depuis Prefect
dbt_cli_profile = DbtCliProfile.load(profile_block_name)
```

**Ce qui se passe en coulisses** :
1. Prefect contacte son API (local ou cloud)
2. RÃ©cupÃ¨re le bloc avec ce nom
3. Le bloc contient toute la config : projet GCP, dataset, credentials, threads
4. Le profil est prÃªt Ã  Ãªtre utilisÃ© par dbt

#### C) Gestion d'Erreur Explicite

**Ajout de try/except** :
```python
try:
    dbt_cli_profile = DbtCliProfile.load(profile_block_name)
    logger.info(f"âœ… Profil chargÃ©: {dbt_cli_profile.name}")
except ValueError as e:
    logger.error(f"âŒ Impossible de charger le bloc '{profile_block_name}'")
    logger.error("Assurez-vous d'avoir exÃ©cutÃ© le setup")
    raise ValueError("Instructions dÃ©taillÃ©es...") from e
```

**Pourquoi ?**
- âœ… UX : Messages d'erreur clairs pour l'utilisateur
- âœ… Debug : Indique exactement quoi faire en cas de problÃ¨me
- âœ… Robustesse : Ã‰vite des erreurs cryptiques

#### D) Propagation du ParamÃ¨tre

**Modification du flow principal** :
```python
@flow(name="pipeline-dbt-complet")
def dbt_full_pipeline(target: str = "dev"):
    # Le paramÃ¨tre est propagÃ© Ã  toutes les tÃ¢ches
    run_result = run_dbt_models(target=target)
    test_result = test_dbt_models(target=target)
    
    return {
        "target": target,  # On retourne aussi le target utilisÃ©
        "run": run_result,
        "test": test_result,
    }
```

## ğŸ§  Concepts et Logique

### 1. Separation of Concerns (SÃ©paration des ResponsabilitÃ©s)

**Principe** : Chaque partie du code a une responsabilitÃ© unique et bien dÃ©finie.

| Module | ResponsabilitÃ© | FrÃ©quence |
|--------|----------------|-----------|
| `infrastructure/setup_profiles/` | **Configuration** : CrÃ©e les blocs | Une fois |
| `prefect_flows/pipeline.py` | **ExÃ©cution** : Utilise les blocs | Souvent |

**Avantages** :
- âœ… MaintenabilitÃ© : Changement de config ? Modifiez seulement setup
- âœ… TestabilitÃ© : On peut tester setup et pipeline sÃ©parÃ©ment
- âœ… ClartÃ© : Chaque fichier a un rÃ´le clair

### 2. Dependency Injection (Injection de DÃ©pendances)

**Concept** : Au lieu de crÃ©er les objets dont on a besoin, on les **injecte** de l'extÃ©rieur.

**Avant (crÃ©ation inline)** :
```python
def run_dbt_models():
    # On crÃ©e tout nous-mÃªmes
    credentials = GcpCredentials(project=..., service_account_info=...)
    target_configs = BigQueryTargetConfigs(...)
    dbt_cli_profile = DbtCliProfile(...)
    # Beaucoup de code dupliquÃ© !
```

**AprÃ¨s (injection via blocs)** :
```python
def run_dbt_models(target: str = "dev"):
    # On charge un objet prÃ©-configurÃ©
    dbt_cli_profile = DbtCliProfile.load(f"dbt-cli-profile-{target}")
    # Simple et rÃ©utilisable !
```

**Avantages** :
- âœ… DRY (Don't Repeat Yourself)
- âœ… Configuration centralisÃ©e
- âœ… Moins de code = moins de bugs

### 3. Configuration as Code

**Principe** : La configuration est du code versionnÃ©, pas des fichiers manuels.

**Flow de configuration** :
```
1. Terraform â†’ CrÃ©e ressources GCP
2. setup_profiles â†’ Lit outputs Terraform
3. setup_profiles â†’ CrÃ©e blocs Prefect
4. pipeline.py â†’ Utilise les blocs
```

**Avantages** :
- âœ… Versionning : Git track les changements
- âœ… ReproductibilitÃ© : MÃªme config = mÃªme rÃ©sultat
- âœ… Automatisation : Pas de configuration manuelle

### 4. Environment Parameterization (ParamÃ©trisation d'Environnement)

**Pattern** : Un seul code, plusieurs environnements via paramÃ¨tres.

**ImplÃ©mentation** :
```python
# DEV
dbt_full_pipeline(target="dev")
# â†’ Charge dbt-cli-profile-dev
# â†’ Dataset dev, 1 thread

# PROD  
dbt_full_pipeline(target="prod")
# â†’ Charge dbt-cli-profile-prod
# â†’ Dataset prod, 4 threads
```

**Avantages** :
- âœ… Pas de duplication de code (pas de pipeline_dev.py et pipeline_prod.py)
- âœ… CohÃ©rence entre environnements
- âœ… FacilitÃ© d'ajout d'environnements (staging, test, etc.)

### 5. Fail-Fast avec Messages Explicites

**Principe** : Ã‰chouer rapidement avec des messages clairs plutÃ´t que continuer avec une erreur cachÃ©e.

**ImplÃ©mentation** :
```python
try:
    dbt_cli_profile = DbtCliProfile.load(profile_block_name)
except ValueError as e:
    # Message explicite
    logger.error(f"âŒ Bloc '{profile_block_name}' introuvable")
    logger.error("Commande Ã  exÃ©cuter :")
    logger.error("  uv run python -m infrastructure.setup_profiles")
    # Raise avec contexte
    raise ValueError("Message dÃ©taillÃ©...") from e
```

**Avantages** :
- âœ… Debug facile : L'erreur dit exactement quoi faire
- âœ… UX dÃ©veloppeur : Pas besoin de deviner
- âœ… Documentation inline : Le code enseigne son utilisation

### 6. Retry Strategy pour la RÃ©silience

**Pattern** : RÃ©essayer automatiquement en cas d'Ã©chec temporaire.

**ImplÃ©mentation** :
```python
@task(name="dbt-run", retries=2, retry_delay_seconds=30)
def run_dbt_models(target: str = "dev"):
    # Si Ã§a Ã©choue, Prefect rÃ©essaie 2 fois avec 30s d'attente
```

**Pourquoi ?**
- BigQuery peut avoir des **rate limits** temporaires
- Les connexions rÃ©seau peuvent Ãªtre **instables**
- Les requÃªtes complexes peuvent **timeout** occasionnellement

**StratÃ©gie** :
- Run : 2 retries (total 3 tentatives) avec 30s d'attente
- Test : 1 retry (total 2 tentatives) car moins critique

## ğŸ”„ Flux d'ExÃ©cution Complet

### Setup Initial (Une fois)

```bash
# 1. CrÃ©er l'infrastructure GCP
cd infrastructure
terraform apply
terraform output -json > terraform-outputs.json

# 2. CrÃ©er les blocs Prefect
cd ..
uv run python -m infrastructure.setup_profiles
```

**Ce qui est crÃ©Ã©** :
```
Prefect Blocks crÃ©Ã©s :
â”œâ”€â”€ gcp-credentials
â”œâ”€â”€ bigquery-target-configs-dev
â”œâ”€â”€ bigquery-target-configs-prod
â”œâ”€â”€ dbt-cli-profile-dev
â”‚   â”œâ”€â”€ name: "projet_m2_bi"
â”‚   â”œâ”€â”€ target: "dev"
â”‚   â”œâ”€â”€ dataset: "decisive_plasma_473714_i8_dev"
â”‚   â”œâ”€â”€ threads: 1
â”‚   â””â”€â”€ credentials: â†’ gcp-credentials
â””â”€â”€ dbt-cli-profile-prod
    â”œâ”€â”€ name: "projet_m2_bi"
    â”œâ”€â”€ target: "prod"
    â”œâ”€â”€ dataset: "decisive_plasma_473714_i8_prod"
    â”œâ”€â”€ threads: 4
    â””â”€â”€ credentials: â†’ gcp-credentials
```

### ExÃ©cution de la Pipeline (Ã€ chaque run)

```bash
# ExÃ©cuter sur dev
uv run python prefect_flows/pipeline.py
```

**Ce qui se passe** :

1. **DÃ©marrage du flow** : `dbt_full_pipeline(target="dev")`

2. **TÃ¢che 1 - run_dbt_models** :
   ```
   a. Construction du nom : "dbt-cli-profile-dev"
   b. Chargement du bloc depuis Prefect
   c. Le bloc contient toute la config
   d. ExÃ©cution de "dbt run" avec cette config
   e. Si Ã©chec â†’ Retry (2x max)
   ```

3. **TÃ¢che 2 - test_dbt_models** :
   ```
   a. Construction du nom : "dbt-cli-profile-dev"
   b. Chargement du bloc depuis Prefect
   c. ExÃ©cution de "dbt test" avec cette config
   d. Si Ã©chec â†’ Retry (1x max)
   ```

4. **Retour du rÃ©sultat** :
   ```json
   {
     "target": "dev",
     "run": <rÃ©sultat dbt run>,
     "test": <rÃ©sultat dbt test>
   }
   ```

## ğŸ“Š Comparaison Avant/AprÃ¨s

### Avant

**ProblÃ¨mes** :
- âŒ Profil hardcodÃ© inexistant
- âŒ Impossible de changer d'environnement
- âŒ Configuration dupliquÃ©e
- âŒ Pas de gestion d'erreur
- âŒ Code couplÃ© Ã  un seul environnement

### AprÃ¨s

**AmÃ©liorations** :
- âœ… Chargement dynamique des blocs Prefect
- âœ… ParamÃ¨tre `target` pour choisir l'environnement
- âœ… Configuration centralisÃ©e dans les blocs
- âœ… Gestion d'erreur explicite
- âœ… Code dÃ©couplÃ© et rÃ©utilisable

## ğŸš€ Utilisation Pratique

### DÃ©veloppement Local

```bash
# Tester sur dev
uv run python prefect_flows/pipeline.py

# Pour tester sur prod, modifier dans pipeline.py :
# dbt_full_pipeline(target="prod")
```

### Avec Prefect Cloud

```bash
# CrÃ©er un deployment pour dev
prefect deployment build prefect_flows/pipeline.py:dbt_full_pipeline \
  -n "dbt-dev" \
  --param target=dev

# CrÃ©er un deployment pour prod
prefect deployment build prefect_flows/pipeline.py:dbt_full_pipeline \
  -n "dbt-prod" \
  --param target=prod

# Appliquer les deployments
prefect deployment apply dbt_full_pipeline-deployment.yaml

# ExÃ©cuter
prefect deployment run pipeline-dbt-complet/dbt-dev
prefect deployment run pipeline-dbt-complet/dbt-prod

# Scheduler (tous les jours Ã  2h du matin)
prefect deployment schedule create pipeline-dbt-complet/dbt-prod \
  --cron "0 2 * * *"
```

## ğŸ“ LeÃ§ons ClÃ©s

### 1. SÃ©paration Setup vs ExÃ©cution
**Setup** crÃ©e la configuration, **ExÃ©cution** l'utilise. Cela permet de changer la config sans toucher au code d'exÃ©cution.

### 2. Convention de Nommage
`dbt-cli-profile-{target}` est une convention. Respecter les conventions rend le code prÃ©visible.

### 3. ParamÃ¨tres par DÃ©faut
`target: str = "dev"` signifie que dev est l'environnement par dÃ©faut. Pratique pour le dÃ©veloppement local.

### 4. Gestion d'Erreur PrÃ©ventive
Mieux vaut un message clair qui dit "ExÃ©cutez cette commande" qu'une stack trace cryptique.

### 5. Documentation dans le Code
Les docstrings dÃ©taillÃ©es et les commentaires expliquent le "pourquoi", pas juste le "quoi".

## ğŸ”® Prochaines Ã‰tapes

Maintenant que la pipeline est configurÃ©e, vous pouvez :

1. **DÃ©velopper vos modÃ¨les dbt** dans `dbt/models/`
2. **Tester localement** : `cd dbt && dbt run --target dev`
3. **ExÃ©cuter via Prefect** : `uv run python prefect_flows/pipeline.py`
4. **Ajouter d'autres tÃ¢ches** : docs, snapshots, seeds, etc.
5. **Configurer le monitoring** : alertes, mÃ©triques, logs
6. **DÃ©ployer sur Prefect Cloud** : scheduling, UI, collaboration

## ğŸ“š RÃ©sumÃ© des Fichiers ModifiÃ©s

| Fichier | Modification | Raison |
|---------|-------------|--------|
| `prefect_flows/pipeline.py` | Ajout paramÃ¨tre `target` | FlexibilitÃ© dev/prod |
| `prefect_flows/pipeline.py` | Chargement dynamique blocs | Utiliser setup existant |
| `prefect_flows/pipeline.py` | Gestion d'erreur | UX et robustesse |
| `prefect_flows/pipeline.py` | Import `get_run_logger` | Meilleur logging |
| `prefect_flows/README.md` | CrÃ©ation | Documentation |
| `documentation/explication_pipeline_prefect.md` | CrÃ©ation | Concepts et apprentissage |

